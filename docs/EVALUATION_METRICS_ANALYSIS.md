# 评测指标分析与改进报告 (Evaluation Metrics Analysis)

本文档旨在分析当前消融实验框架中使用的各项评测指标，解释其计算逻辑、设计初衷，并指出在当前三分类场景下的局限性。

---

## 1. 现有指标体系 (Current Metrics)

目前的评测体系主要围绕 **风险等级预测**、**证据准确性** 和 **规则触发** 三个维度展开。

### 1.1 风险等级准确性 (Risk Level Accuracy)

| 指标 | 变量名 | 计算逻辑 | 说明 |
| :--- | :--- | :--- | :--- |
| **准确率** | `accuracy` | `Correct / Total` | 只有当预测等级与真实等级完全一致（精确字符串匹配）时才算正确。 |
| **加权准确率** | `weighted_accuracy` | `Total Score / Total Samples` | 考虑了错误的严重程度：<br>• **精确匹配**: 1分<br>• **差一级** (高↔中, 中↔低): 0.5分<br>• **差两级** (高↔低): 0分 |

### 1.2 二分类指标 (Binary Classification Metrics)

目前将问题简化为 **"有风险 (Positive)" vs "无风险 (Negative)"** 的二分类问题进行计算。
- **Positive (阳性)**: 高风险 (High) 或 中风险 (Medium)
- **Negative (阴性)**: 低风险 (Low)

| 指标 | 变量名 | 计算逻辑 | 局限性分析 |
| :--- | :--- | :--- | :--- |
| **精确率** | `precision` | `TP / (TP + FP)` | 在所有被模型预测为"有风险"的样本中，实际确实"有风险"的比例。 |
| **召回率** | `recall` | `TP / (TP + FN)` | 在所有实际"有风险"的样本中，被模型成功抓出来的比例。<br>⚠️ **局限**: 如果模型倾向于把所有样本都判为"高风险"，Recall 会是 100%，掩盖了其无法区分"中风险"和"无风险"的问题。 |
| **F1 Score** | `f1` | `2 * P * R / (P + R)` | 精确率和召回率的调和平均数。 |

### 1.3 幻觉检测指标 (Hallucination Metrics)

衡量 LLM 生成的证据是否忠实于原文或法律事实。

| 指标 | 变量名 | 逻辑 |
| :--- | :--- | :--- |
| **总幻觉率** | `hallucination_rate` | `(条款幻觉 + 法条幻觉) / 总证据数` |
| **条款幻觉率** | `clause_hallucination_rate` | 使用 **BGE-M3 + Reranker** 两阶段验证。<br>如果 LLM 引用的原文在原合同中找不到语义相似度 > 0.3 的句子，则视为幻觉。 |
| **法条幻觉率** | `law_hallucination_rate` | 验证法律引用是否规范、是否存在于白名单/数据库中。<br>*(注：低风险样本现已跳过此验证)* |

### 1.4 其他指标

- **任务成功率 (`task_success_rate`)**: 苛刻指标。要求 **风险等级预测正确** AND **无条款幻觉** AND **无法条幻觉** 才算成功。
- **规则触发指标 (`rule_recall`)**: 衡量 RAG 检索器是否召回了正确的风险规则 ID。
- **平均响应时间 (`avg_latency_sec`)**: 系统处理请求的平均耗时。

---

## 2. 现有体系的局限性 (Limitations)

经过分析，现有体系主要存在以下两个核心问题：

### 2.1 样本不平衡与随机性 (Imbalance & Randomness)
- **现状**: 使用 `random.sample` 进行简单随机采样。
- **问题**: 在小样本测试（如 limit=10）中，可能会偶然抽到 7 个高风险、3 个低风险，导致阳性样本占比过高 (70%)。
- **后果**: 这会人为抬高 Recall（因为阳性多，模型只要倾向报风险就能得分），使评测结果在不同运行间波动巨大，难以横向对比。

### 2.2 二分类视角的不足 (Binary Perspective Limitation)
- **现状**: `High/Medium` 被合并为 `Positive`。
- **问题**: 无法评估模型区分 **"高风险 vs 中风险"** 的能力。
  - 例如：真实标签是 `Medium`，模型预测 `High`。在现有二分类指标下，这被视为 **Correct (TP)**。
  - 实际上：这属于 **过敏 (Over-sensitive)**，即把中风险夸大为高风险，应当受到惩罚。现有指标掩盖了这一错误。

---

## 3. 改进方案 (Proposed Improvements)

为了解决上述问题，建议引入 **分层采样** 和 **三分类指标**。

### 3.1 采样策略：分层采样 (Stratified Sampling)
强制要求每次评测的样本分布为 **高:中:低 = 1:1:1**。
- **实施**: 如果 limit=12，则强制抽取 4条高风险、4条中风险、4条低风险。
- **收益**: 消除随机偏差，确保各类样本权重一致。

### 3.2 评测指标：三分类体系 (Multi-class Metrics)

引入以下指标替代单一的 P/R/F1：

1.  **Macro-F1 (宏平均 F1)**
    - 分别计算 High、Medium、Low 三类的 F1 值，然后取平均。
    - `Macro-F1 = (F1_High + F1_Medium + F1_Low) / 3`
    - 能平等反映模型在所有类别上的表现。

2.  **Cohen's Kappa (或 Quadratic Weighted Kappa)**
    - **定义**: 衡量两个评分者（模型 vs 真实标签）一致性的统计量，排除了随机猜对的可能性。
    - **加权 (Quadratic Weighted)**: 考虑错误的严重程度。
      - 预测 High 但实际 High：满分
      - 预测 High 但实际 Medium：轻微惩罚
      - 预测 High 但实际 Low：严重惩罚
    - **优势**: 非常适合 **有序分类 (Ordinal Classification)** 问题（高 > 中 > 低）。

3.  **混淆矩阵 (Confusion Matrix)**
    - 输出 3x3 矩阵，直观展示误判流向。

---

## 4. 结论

建议立即实施 **分层采样** 和 **三分类指标** 的改造，以获得更客观、更稳定的评测结果。这尤其对于微调 Prompt 区分 "高/中" 风险至关重要。
